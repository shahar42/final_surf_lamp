Infrastructure Layer Complete Specification
==========================================

DOMAIN RESPONSIBILITY: External APIs, security services, configuration, deployment, monitoring
FORBIDDEN: Business logic, database schema design, API endpoints, cache implementation logic

INTERFACE CONTRACTS TO IMPLEMENT:
=================================

YOU MUST IMPLEMENT these interfaces:

1. ISurfDataProvider - External surf API integration with multi-provider fallback
2. IPasswordSecurity - Secure password hashing and verification  
3. IInputValidator - Comprehensive input validation services

REQUIRED DIRECTORY STRUCTURE:
============================

Create these files:
```
app/infrastructure/
├── external/
│   ├── surf_providers/
│   │   ├── base_provider.py         # Abstract base provider
│   │   ├── surfline_provider.py     # Surfline API integration
│   │   ├── weather_api_provider.py  # WeatherAPI integration
│   │   └── multi_provider_service.py # ISurfDataProvider implementation
│   └── http_client.py               # Shared HTTP client with retry logic
├── security/
│   ├── password_security.py         # IPasswordSecurity implementation
│   └── input_validator.py           # IInputValidator implementation
├── config/
│   ├── settings.py                  # Application configuration
│   ├── logging_config.py            # Structured logging setup
│   └── monitoring.py                # Metrics and health monitoring
├── deployment/
│   ├── Dockerfile                   # Container configuration
│   ├── docker-compose.yml           # Multi-container setup
│   ├── docker-compose.prod.yml      # Production configuration
│   └── nginx.conf                   # Reverse proxy configuration
└── monitoring/
    ├── metrics.py                   # Prometheus metrics
    └── health_checks.py             # System health monitoring
```

EXTERNAL SURF API INTEGRATION:
==============================

1. LOCATION MAPPING CONFIGURATION
   -------------------------------

   Static Configuration:
   ```python
   LOCATION_MAPPINGS = {
       0: {  # San Diego
           "name": "San Diego",
           "state": "CA",
           "coordinates": {"lat": 32.7157, "lon": -117.1611},
           "surfline_spot_id": "5842041f4e65fad6a7708876",
           "timezone": "America/Los_Angeles"
       },
       1: {  # Santa Cruz
           "name": "Santa Cruz", 
           "state": "CA",
           "coordinates": {"lat": 36.9741, "lon": -122.0308},
           "surfline_spot_id": "5842041f4e65fad6a7708877",
           "timezone": "America/Los_Angeles"
       },
       2: {  # Honolulu
           "name": "Honolulu",
           "state": "HI", 
           "coordinates": {"lat": 21.3099, "lon": -157.8581},
           "surfline_spot_id": "5842041f4e65fad6a7708878",
           "timezone": "Pacific/Honolulu"
       },
       3: {  # Huntington Beach
           "name": "Huntington Beach",
           "state": "CA",
           "coordinates": {"lat": 33.6595, "lon": -117.9988},
           "surfline_spot_id": "5842041f4e65fad6a7708879", 
           "timezone": "America/Los_Angeles"
       },
       4: {  # Malibu
           "name": "Malibu",
           "state": "CA",
           "coordinates": {"lat": 34.0259, "lon": -118.7798},
           "surfline_spot_id": "5842041f4e65fad6a770887a",
           "timezone": "America/Los_Angeles"
       }
   }
   ```

2. SURFLINE API PROVIDER (PRIMARY)
   --------------------------------

   Class: SurflineProvider(BaseSurfProvider)

   API Configuration:
   - Base URL: https://services.surfline.com/kbyg/spots/forecasts
   - Authentication: API Key in headers
   - Rate Limits: 1000 requests/day  
   - Response Format: Complex nested JSON
   - Data Quality: High (professional surf forecasting)

   Implementation:
   ```python
   async def fetch_surf_data(self, location_index: int) -> Optional[SurfData]:
       location_config = LOCATION_MAPPINGS.get(location_index)
       if not location_config:
           raise ValidationError(f"Unsupported location index: {location_index}")
       
       spot_id = location_config["surfline_spot_id"]
       url = f"{self.base_url}/{spot_id}"
       
       headers = {
           "Authorization": f"Bearer {self.api_key}",
           "User-Agent": "SurfboardLamp/1.0",
           "Accept": "application/json"
       }
       
       params = {
           "days": 1,
           "intervalHours": 1,
           "maxHeights": "true"
       }
       
       try:
           async with self.http_client.get(url, headers=headers, params=params, timeout=30) as response:
               if response.status == 200:
                   data = await response.json()
                   return self._parse_surfline_response(data, location_config)
               elif response.status == 429:  # Rate limited
                   logger.warning("Surfline rate limit exceeded")
                   raise APIRateLimitError("Surfline API rate limit exceeded")
               elif response.status == 401:  # Invalid API key
                   logger.error("Surfline API authentication failed")
                   raise APIAuthenticationError("Invalid Surfline API key")
               else:
                   logger.error("Surfline API error", status=response.status)
                   raise APIError(f"Surfline API returned {response.status}")
                   
       except asyncio.TimeoutError:
           logger.error("Surfline API timeout", location_index=location_index)
           raise APITimeoutError("Surfline API request timed out")
   ```

   Surfline Response Parsing:
   ```python
   def _parse_surfline_response(self, data: Dict[str, Any], location_config: Dict[str, Any]) -> SurfData:
       try:
           # Extract current conditions from Surfline's complex nested structure
           forecasts = data.get("data", {}).get("wave", [])
           if not forecasts:
               raise APIError("No wave data in Surfline response")
           
           current_forecast = forecasts[0]  # First entry is current conditions
           
           # Parse wave data
           wave_height = current_forecast.get("surf", {}).get("max", 0)  # feet
           wave_period = current_forecast.get("swells", [{}])[0].get("period", 0)  # seconds
           
           # Parse wind data  
           wind_data = data.get("data", {}).get("wind", [{}])[0]
           wind_speed = wind_data.get("speed", 0)  # knots
           wind_direction = wind_data.get("direction", 0)  # degrees
           
           # Convert units
           wave_height_m = wave_height * 0.3048  # feet to meters
           wind_speed_mps = wind_speed * 0.514444  # knots to m/s
           
           return SurfData({
               "wave_height_m": round(wave_height_m, 2),
               "wave_period_s": wave_period,
               "wind_speed_mps": round(wind_speed_mps, 2),
               "wind_deg": int(wind_direction),
               "location_name": location_config["name"],
               "timestamp": time.time(),
               "data_source": "surfline"
           })
           
       except Exception as e:
           logger.error("Surfline response parsing failed", error=str(e), raw_data=data)
           raise APIError(f"Failed to parse Surfline response: {e}")
   ```

3. WEATHER API PROVIDER (FALLBACK)
   --------------------------------

   Class: WeatherAPIProvider(BaseSurfProvider)

   API Configuration:
   - Base URL: https://api.weatherapi.com/v1/marine.json
   - Authentication: API Key parameter
   - Rate Limits: 100,000 requests/month (free tier)
   - Response Format: Simple JSON
   - Data Quality: Medium (general weather data)

   Implementation:
   ```python
   async def fetch_surf_data(self, location_index: int) -> Optional[SurfData]:
       location_config = LOCATION_MAPPINGS.get(location_index)
       if not location_config:
           raise ValidationError(f"Unsupported location index: {location_index}")
       
       coords = location_config["coordinates"]
       lat_lon = f"{coords['lat']},{coords['lon']}"
       
       params = {
           "key": self.api_key,
           "q": lat_lon,
           "days": 1,
           "tp": 1  # 1-hour intervals
       }
       
       try:
           async with self.http_client.get(self.base_url, params=params, timeout=30) as response:
               if response.status == 200:
                   data = await response.json()
                   return self._parse_weather_api_response(data, location_config)
               elif response.status == 429:
                   logger.warning("WeatherAPI rate limit exceeded")
                   raise APIRateLimitError("WeatherAPI rate limit exceeded")
               elif response.status == 401:
                   logger.error("WeatherAPI authentication failed")
                   raise APIAuthenticationError("Invalid WeatherAPI key")
               else:
                   logger.error("WeatherAPI error", status=response.status)
                   raise APIError(f"WeatherAPI returned {response.status}")
                   
       except asyncio.TimeoutError:
           logger.error("WeatherAPI timeout", location_index=location_index)
           raise APITimeoutError("WeatherAPI request timed out")
   ```

   WeatherAPI Response Parsing:
   ```python
   def _parse_weather_api_response(self, data: Dict[str, Any], location_config: Dict[str, Any]) -> SurfData:
       try:
           marine_data = data.get("forecast", {}).get("forecastday", [{}])[0].get("hour", [{}])[0]
           
           # Extract marine data
           wave_height = marine_data.get("sig_ht_mt", 0)  # meters
           wave_period = marine_data.get("swell_period_secs", 0)  # seconds
           wind_speed = marine_data.get("wind_kph", 0)  # km/h
           wind_direction = marine_data.get("wind_degree", 0)  # degrees
           
           # Convert wind speed from km/h to m/s
           wind_speed_mps = wind_speed / 3.6
           
           return SurfData({
               "wave_height_m": round(wave_height, 2),
               "wave_period_s": wave_period,
               "wind_speed_mps": round(wind_speed_mps, 2),
               "wind_deg": int(wind_direction),
               "location_name": location_config["name"],
               "timestamp": time.time(),
               "data_source": "weatherapi"
           })
           
       except Exception as e:
           logger.error("WeatherAPI response parsing failed", error=str(e), raw_data=data)
           raise APIError(f"Failed to parse WeatherAPI response: {e}")
   ```

4. MULTI-PROVIDER SERVICE (ISurfDataProvider IMPLEMENTATION)
   --------------------------------------------------------

   Class: MultiProviderSurfDataService(ISurfDataProvider)

   Provider Priority and Fallback Logic:
   ```python
   async def fetch_surf_data(self, location_index: int) -> Optional[SurfData]:
       providers = [
           ("surfline", self.surfline_provider),
           ("weatherapi", self.weather_api_provider)
       ]
       
       last_error = None
       
       for provider_name, provider in providers:
           try:
               logger.info("Attempting data fetch", 
                          provider=provider_name, 
                          location_index=location_index)
               
               surf_data = await provider.fetch_surf_data(location_index)
               
               if surf_data and surf_data.is_complete:
                   logger.info("Surf data fetch successful", 
                              provider=provider_name,
                              location_index=location_index,
                              wave_height=surf_data.get("wave_height_m"))
                   
                   # Record provider success metrics
                   await self._record_provider_success(provider_name)
                   return surf_data
               
           except APIRateLimitError as e:
               logger.warning("Provider rate limited, trying next", 
                            provider=provider_name, 
                            error=str(e))
               await self._record_provider_error(provider_name, "rate_limit")
               last_error = e
               continue
               
           except APIAuthenticationError as e:
               logger.error("Provider authentication failed", 
                          provider=provider_name, 
                          error=str(e))
               await self._record_provider_error(provider_name, "auth_error")
               last_error = e
               continue
               
           except (APITimeoutError, APIError) as e:
               logger.warning("Provider failed, trying next", 
                            provider=provider_name, 
                            error=str(e))
               await self._record_provider_error(provider_name, "api_error") 
               last_error = e
               continue
               
           except Exception as e:
               logger.error("Unexpected provider error", 
                          provider=provider_name, 
                          error=str(e))
               await self._record_provider_error(provider_name, "unexpected_error")
               last_error = e
               continue
       
       # All providers failed
       logger.error("All surf data providers failed", 
                   location_index=location_index, 
                   last_error=str(last_error))
       return None
   ```

   API Key Validation:
   ```python
   async def validate_api_keys(self) -> Dict[str, bool]:
       validation_results = {}
       
       # Test Surfline API
       try:
           test_data = await self.surfline_provider.fetch_surf_data(0)  # Test with San Diego
           validation_results["surfline"] = test_data is not None
       except APIAuthenticationError:
           validation_results["surfline"] = False
       except Exception:
           validation_results["surfline"] = False
       
       # Test WeatherAPI  
       try:
           test_data = await self.weather_api_provider.fetch_surf_data(0)
           validation_results["weatherapi"] = test_data is not None
       except APIAuthenticationError:
           validation_results["weatherapi"] = False
       except Exception:
           validation_results["weatherapi"] = False
       
       return validation_results
   ```

SECURITY SERVICES:
=================

1. PASSWORD SECURITY (IPasswordSecurity)
   --------------------------------------

   Class: BCryptPasswordSecurity(IPasswordSecurity)

   Implementation:
   ```python
   import bcrypt
   import secrets
   from typing import AsyncGenerator
   
   class BCryptPasswordSecurity(IPasswordSecurity):
       def __init__(self, rounds: int = 12):
           self.rounds = rounds
           self._validate_rounds()
       
       def _validate_rounds(self):
           if self.rounds < 10 or self.rounds > 15:
               raise ValueError("BCrypt rounds must be between 10 and 15")
       
       async def hash_password(self, password: str) -> str:
           """Hash password using bcrypt with salt"""
           if not password or len(password) < 8:
               raise ValidationError("Password must be at least 8 characters")
           
           # Generate salt and hash
           salt = bcrypt.gensalt(rounds=self.rounds)
           hashed = bcrypt.hashpw(password.encode('utf-8'), salt)
           
           return hashed.decode('utf-8')
       
       async def verify_password(self, password: str, hashed: str) -> bool:
           """Verify password against hash with timing attack protection"""
           if not password or not hashed:
               return False
           
           try:
               return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))
           except Exception as e:
               logger.error("Password verification error", error=str(e))
               return False
       
       def generate_secure_token(self, length: int = 32) -> str:
           """Generate cryptographically secure random token"""
           return secrets.token_urlsafe(length)
   ```

2. INPUT VALIDATOR (IInputValidator)
   ---------------------------------

   Class: SecurityInputValidator(IInputValidator)

   Implementation:
   ```python
   import re
   import uuid
   from typing import Set
   
   class SecurityInputValidator(IInputValidator):
       def __init__(self):
           self.email_pattern = re.compile(
               r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
           )
           self.supported_locations: Set[int] = set(range(5))  # 0-4
           self.lamp_id_pattern = re.compile(r'^[a-zA-Z0-9_-]{3,50}$')
       
       async def validate_email(self, email: str) -> bool:
           """Validate email format using RFC-compliant regex"""
           if not email or len(email) > 254:  # RFC 5321 limit
               return False
           
           return bool(self.email_pattern.match(email.lower()))
       
       async def validate_lamp_id(self, lamp_id: str) -> bool:
           """Validate lamp ID format"""
           if not lamp_id:
               return False
           
           # Try UUID format first
           try:
               uuid.UUID(lamp_id)
               return True
           except ValueError:
               pass
           
           # Try custom format (LAMP_XXXXXX or alphanumeric)
           return bool(self.lamp_id_pattern.match(lamp_id))
       
       async def validate_location_index(self, location_index: int) -> bool:
           """Validate location index is supported"""
           return location_index in self.supported_locations
       
       async def validate_password_strength(self, password: str) -> Dict[str, bool]:
           """Comprehensive password strength validation"""
           if not password:
               return {"valid": False, "errors": ["Password is required"]}
           
           checks = {
               "min_length": len(password) >= 8,
               "max_length": len(password) <= 128,
               "has_uppercase": bool(re.search(r'[A-Z]', password)),
               "has_lowercase": bool(re.search(r'[a-z]', password)),
               "has_digit": bool(re.search(r'\d', password)),
               "has_special": bool(re.search(r'[!@#$%^&*(),.?":{}|<>]', password)),
               "no_common_patterns": not self._has_common_patterns(password)
           }
           
           errors = []
           if not checks["min_length"]:
               errors.append("Password must be at least 8 characters")
           if not checks["max_length"]:
               errors.append("Password must be less than 128 characters")
           if not checks["has_digit"]:
               errors.append("Password must contain at least one number")
           if not checks["has_uppercase"]:
               errors.append("Password must contain at least one uppercase letter")
           if not checks["has_lowercase"]:
               errors.append("Password must contain at least one lowercase letter")
           if not checks["no_common_patterns"]:
               errors.append("Password contains common patterns")
           
           return {
               "valid": all(checks.values()),
               "errors": errors,
               "strength_score": sum(checks.values()) / len(checks)
           }
       
       def _has_common_patterns(self, password: str) -> bool:
           """Check for common weak patterns"""
           common_patterns = [
               "password", "123456", "qwerty", "admin", "login",
               "welcome", "monkey", "dragon", "master", "shadow"
           ]
           
           password_lower = password.lower()
           return any(pattern in password_lower for pattern in common_patterns)
   ```

APPLICATION CONFIGURATION:
=========================

Settings Management (Pydantic):
```python
from pydantic_settings import BaseSettings
from typing import Optional, List

class SurfLampSettings(BaseSettings):
    """Application configuration using environment variables"""
    
    # Application
    app_name: str = "Surfboard Lamp Backend"
    app_version: str = "1.0.0"
    debug: bool = False
    
    # Database
    database_url: str
    database_pool_min_size: int = 5
    database_pool_max_size: int = 20
    
    # Redis
    redis_url: str = "redis://localhost:6379"
    redis_password: Optional[str] = None
    
    # External APIs
    surfline_api_key: Optional[str] = None
    weather_api_key: Optional[str] = None
    api_request_timeout: int = 30
    api_max_retries: int = 3
    
    # Security
    secret_key: str
    password_hash_rounds: int = 12
    session_lifetime_hours: int = 24
    
    # Cache Settings
    surf_data_cache_ttl: int = 1800  # 30 minutes
    location_cache_ttl: int = 3600   # 1 hour
    
    # Monitoring
    log_level: str = "INFO"
    enable_metrics: bool = True
    metrics_port: int = 9090
    
    # Performance
    max_concurrent_requests: int = 100
    background_job_interval: int = 30  # minutes
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False
    
    @property
    def is_production(self) -> bool:
        return not self.debug
    
    @property
    def has_surf_apis(self) -> bool:
        return bool(self.surfline_api_key or self.weather_api_key)
    
    def get_cors_origins(self) -> List[str]:
        if self.debug:
            return ["*"]
        return ["https://surflamp.com", "https://app.surflamp.com"]
```

DOCKER DEPLOYMENT:
=================

1. DOCKERFILE
   ----------

   ```dockerfile
   # Multi-stage build for production optimization
   FROM python:3.11-slim as builder
   
   # Install build dependencies
   RUN apt-get update && apt-get install -y \
       gcc \
       g++ \
       && rm -rf /var/lib/apt/lists/*
   
   # Install Python dependencies
   COPY requirements.txt .
   RUN pip install --user --no-cache-dir -r requirements.txt
   
   # Production stage
   FROM python:3.11-slim
   
   # Create app user for security
   RUN useradd --create-home --shell /bin/bash app
   
   # Install runtime dependencies
   RUN apt-get update && apt-get install -y \
       curl \
       && rm -rf /var/lib/apt/lists/*
   
   # Copy Python packages from builder
   COPY --from=builder /root/.local /home/app/.local
   
   # Set up application directory
   WORKDIR /app
   COPY --chown=app:app . .
   
   # Switch to app user
   USER app
   
   # Add local Python packages to PATH
   ENV PATH=/home/app/.local/bin:$PATH
   
   # Health check
   HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
       CMD curl -f http://localhost:8000/health || exit 1
   
   # Expose port
   EXPOSE 8000
   
   # Start application
   CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
   ```

2. DOCKER COMPOSE (DEVELOPMENT)
   ----------------------------

   ```yaml
   version: '3.8'
   
   services:
     backend:
       build: .
       ports:
         - "8000:8000"
       environment:
         - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/surflamp
         - REDIS_URL=redis://redis:6379
         - SURFLINE_API_KEY=${SURFLINE_API_KEY}
         - WEATHER_API_KEY=${WEATHER_API_KEY}
         - SECRET_KEY=${SECRET_KEY}
         - DEBUG=true
       depends_on:
         db:
           condition: service_healthy
         redis:
           condition: service_healthy
       volumes:
         - .:/app
       restart: unless-stopped
   
     db:
       image: postgres:15
       environment:
         - POSTGRES_USER=postgres
         - POSTGRES_PASSWORD=${DB_PASSWORD}
         - POSTGRES_DB=surflamp
       ports:
         - "5432:5432"
       volumes:
         - postgres_data:/var/lib/postgresql/data
         - ./app/data_layer/migrations/schema.sql:/docker-entrypoint-initdb.d/init.sql
       healthcheck:
         test: ["CMD-SHELL", "pg_isready -U postgres"]
         interval: 30s
         timeout: 10s
         retries: 5
   
     redis:
       image: redis:7-alpine
       ports:
         - "6379:6379"
       volumes:
         - redis_data:/data
       healthcheck:
         test: ["CMD", "redis-cli", "ping"]
         interval: 30s
         timeout: 10s
         retries: 5
   
     nginx:
       image: nginx:alpine
       ports:
         - "80:80"
         - "443:443"
       volumes:
         - ./app/infrastructure/deployment/nginx.conf:/etc/nginx/nginx.conf
       depends_on:
         - backend
   
   volumes:
     postgres_data:
     redis_data:
   ```

3. PRODUCTION DOCKER COMPOSE
   -------------------------

   ```yaml
   version: '3.8'
   
   services:
     backend:
       image: surflamp/backend:${VERSION}
       deploy:
         replicas: 3
         resources:
           limits:
             memory: 512M
           reservations:
             memory: 256M
       environment:
         - DATABASE_URL=${DATABASE_URL}
         - REDIS_URL=${REDIS_URL}
         - SURFLINE_API_KEY=${SURFLINE_API_KEY}
         - WEATHER_API_KEY=${WEATHER_API_KEY}
         - SECRET_KEY=${SECRET_KEY}
         - DEBUG=false
         - LOG_LEVEL=INFO
       networks:
         - app_network
       logging:
         driver: "json-file"
         options:
           max-size: "10m"
           max-file: "3"
   
     nginx:
       image: nginx:alpine
       ports:
         - "80:80"
         - "443:443"
       volumes:
         - ./ssl:/etc/nginx/ssl
         - ./nginx.prod.conf:/etc/nginx/nginx.conf
       networks:
         - app_network
   
   networks:
     app_network:
       driver: overlay
   ```

MONITORING AND LOGGING:
======================

1. STRUCTURED LOGGING SETUP
   -------------------------

   ```python
   import structlog
   import logging.config
   from typing import Any, Dict
   
   def setup_logging(log_level: str = "INFO") -> None:
       """Configure structured logging for the application"""
       
       # Configure standard library logging
       logging_config = {
           'version': 1,
           'disable_existing_loggers': False,
           'formatters': {
               'json': {
                   'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
               }
           },
           'handlers': {
               'console': {
                   'class': 'logging.StreamHandler',
                   'formatter': 'json',
                   'stream': 'ext://sys.stdout'
               }
           },
           'root': {
               'level': log_level,
               'handlers': ['console']
           }
       }
       
       logging.config.dictConfig(logging_config)
       
       # Configure structlog
       structlog.configure(
           processors=[
               structlog.stdlib.filter_by_level,
               structlog.stdlib.add_logger_name,
               structlog.stdlib.add_log_level,
               structlog.stdlib.PositionalArgumentsFormatter(),
               structlog.processors.TimeStamper(fmt="iso"),
               structlog.processors.StackInfoRenderer(),
               structlog.processors.format_exc_info,
               structlog.processors.UnicodeDecoder(),
               structlog.processors.JSONRenderer()
           ],
           context_class=dict,
           logger_factory=structlog.stdlib.LoggerFactory(),
           wrapper_class=structlog.stdlib.BoundLogger,
           cache_logger_on_first_use=True,
       )
   ```

2. PROMETHEUS METRICS
   ------------------

   ```python
   from prometheus_client import Counter, Histogram, Gauge, Info
   
   # API Metrics
   SURF_API_REQUESTS = Counter(
       'surf_api_requests_total',
       'Total surf API requests',
       ['provider', 'location', 'status']
   )
   
   SURF_API_DURATION = Histogram(
       'surf_api_request_duration_seconds',
       'Surf API request duration',
       ['provider']
   )
   
   # System Metrics
   ACTIVE_LAMPS = Gauge(
       'active_lamps_total',
       'Number of active lamps'
   )
   
   CACHE_OPERATIONS = Counter(
       'cache_operations_total',
       'Cache operations',
       ['operation', 'result']  # get/set, hit/miss
   )
   
   # Application Info
   APP_INFO = Info(
       'surf_lamp_app',
       'Application information'
   )
   
   def record_api_request(provider: str, location: int, status: str, duration: float):
       SURF_API_REQUESTS.labels(provider=provider, location=location, status=status).inc()
       SURF_API_DURATION.labels(provider=provider).observe(duration)
   ```

3. HEALTH MONITORING
   -----------------

   ```python
   from typing import Dict, Any
   from datetime import datetime
   
   class HealthMonitor:
       def __init__(self, surf_provider: ISurfDataProvider, 
                    cache_manager: ICacheManager,
                    db_pool):
           self.surf_provider = surf_provider
           self.cache_manager = cache_manager
           self.db_pool = db_pool
       
       async def get_system_health(self) -> Dict[str, Any]:
           """Comprehensive system health check"""
           health_status = {
               "status": "healthy",
               "timestamp": datetime.utcnow().isoformat(),
               "version": "1.0.0",
               "components": {}
           }
           
           # Check database
           try:
               async with self.db_pool.acquire() as conn:
                   await conn.fetchval("SELECT 1")
               health_status["components"]["database"] = {"status": "healthy"}
           except Exception as e:
               health_status["components"]["database"] = {
                   "status": "unhealthy", 
                   "error": str(e)
               }
               health_status["status"] = "unhealthy"
           
           # Check Redis cache
           try:
               await self.cache_manager.redis.ping()
               health_status["components"]["cache"] = {"status": "healthy"}
           except Exception as e:
               health_status["components"]["cache"] = {
                   "status": "unhealthy",
                   "error": str(e)
               }
               health_status["status"] = "degraded"
           
           # Check external APIs
           try:
               api_status = await self.surf_provider.validate_api_keys()
               health_status["components"]["external_apis"] = {
                   "status": "healthy" if any(api_status.values()) else "degraded",
                   "providers": api_status
               }
           except Exception as e:
               health_status["components"]["external_apis"] = {
                   "status": "unhealthy",
                   "error": str(e)
               }
           
           return health_status
   ```

CRITICAL SUCCESS CRITERIA:
=========================

The infrastructure layer implementation MUST:
✅ Implement ISurfDataProvider with robust multi-provider fallback
✅ Implement IPasswordSecurity with bcrypt and secure practices
✅ Implement IInputValidator with comprehensive validation rules
✅ Support multiple external surf API providers with rate limiting
✅ Handle all external API errors gracefully without breaking system
✅ Provide secure password hashing with configurable strength
✅ Validate all user inputs according to security best practices
✅ Include production-ready Docker deployment configuration
✅ Implement structured logging and metrics collection
✅ Support environment-based configuration management
✅ Never expose internal system details through external interfaces
✅ Scale efficiently with connection pooling and retry logic

Generate complete, production-ready infrastructure layer following these specifications.
